Ut enim ad minim veniam, quis nostrud exercitation
ullamco laboris nisi ut aliquip ex ea commodo
consequat. Duis aute irure dolor in reprehenderit in
voluptate velit esse cillum dolore eu fugiat nulla pariatur.
Excepteur sint occaecat cupidatat non proident, sunt in
culpa qui officia deserunt mollit anim id est laborum.", 5),
place = rep("Somewhere", 5),
price = c(rep("yes", 3), rep("no", 2)),
website = rep("http://google.com", 5)
# datas for talk example
temp_talks <- data.frame(
title = rep("My Talk", 5),
from = rep("1900-01-01", 5),
to = rep("1900-01-01", 5),
summary = rep("Lorem ipsum dolor sit amet, consectetur
adipiscing elit, sed do eiusmod tempor
incididunt ut labore et dolore magna aliqua.
Ut enim ad minim veniam, quis nostrud exercitation
ullamco laboris nisi ut aliquip ex ea commodo
consequat. Duis aute irure dolor in reprehenderit in
voluptate velit esse cillum dolore eu fugiat nulla pariatur.
Excepteur sint occaecat cupidatat non proident, sunt in
culpa qui officia deserunt mollit anim id est laborum.", 5),
place = rep("Somewhere", 5),
price = c(rep("yes", 3), rep("no", 2)),
website = rep("http://google.com", 5)
# datas for course example
temp_courses <- data.frame(
title = rep("My course", 4),
topic = rep("my topic", 4),
nb_students = c(10, 100, 4, 250),
nb_hours = c(5, 45, 8, 45),
from = rep("1900-01-01", 4),
to = rep("1900-01-01", 4),
place = rep("Somewhere", 4),
supervisor = rep("Somebody", 4),
syllabus = rep("http://google.com", 4)
)
# datas for internship example
temp_internships <- data.frame(
title = c("My Internship 1", "My Internship 2",
"My Internship 3", "My Internship 4"),
topic = rep("some topic", 4),
from = rep("1900-01-01", 4),
to = rep("1900-01-01", 4),
place = rep("Somewhere", 4),
supervisor = rep("Somebody", 4),
level = c("bachelor", "master", "PhD", "PostDoc"),
advert = rep("http://google.com", 4)
)
# ---------------------------------
feed_datas <- feed_shinyCV(temp_profile, temp_about, temp_skills, temp_languages,
temp_network, temp_formations, temp_projects, temp_tasks,
temp_publications, publications_screenshots = list(),
temp_talks, temp_courses, temp_internships)
preview_shinyCV(cv_path, cv_mode = "academic", data_source = "manual", datas = feed_datas)
preview_shinyCV(cv_path, cv_mode = "academic", data_source = "manual", datas = feed_datas)
# --------------------------------------
publish_shinyCV(cv_path)
build_shinyCV()
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
install.packages("shinyLP")
install.packages(c("shinyBS", "shinythemes"))
library(shinyLP)
shinyLP::runExample()
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
devtools::install_github("r-lib/pkgload", force = TRUE)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
install.packages("pkgload")
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
setwd("D:/R/R Project")
# Overview – Linear Regression
# Reading data
housing <- read.csv("USA_Housing.csv",
header = TRUE, sep = ",")
# Overview – Linear Regression
# Reading data
housing <- read.csv("USA_Housing.csv",
header = TRUE, sep = ",")
# Print top 6 observations
head(housing)
# Exploratory Data Analysis
# 1. Checking distribution of target variable – First, you should always try to understand the nature of your target variable. To achieve this, we will be drawing a histogram with a density plot.
library(ggplot2)
# Building histogram
ggplot(data=housing, aes(housing$Price)) +
geom_histogram(aes(y =..density..), fill = "orange") +
geom_density()
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
install.packages("backports")
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
install.packages("htmltools")
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
install.packages("fs")
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
install.packages("seminr")
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
install.packages("rlang")
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
setwd("D:/R/Training/Web Development")
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
install.packages("pander")
data("iris")
kable(summary.aov())
library(knitr)
kable(summary(iris))
knitr::opts_chunk$set(echo = TRUE)
summary(iris)
kable(summary(iris))
library(knitr)
library(rmarkdown)
library(markdown)
summary(iris)
kable(summary(iris))
kable::kable(summary(iris))
kable::summary(iris)
kable(summary(iris))
pander::pander(summary(iris))
cor.test(iris$Sepal.Length, iris$Sepal.Width)
kable(cor.test(iris$Sepal.Length, iris$Sepal.Width))
pander::pander(cor.test(iris$Sepal.Length, iris$Sepal.Width))
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(rmarkdown)
library(markdown)
summary(iris)
kable(summary(iris))
pander::pander(summary(iris))
cor.test(iris$Sepal.Length, iris$Sepal.Width)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
setwd("D:/R/learning/Web Scraping")
library(rvest)
library(dplyr)
# Read html page to scrape
# create a search and copy the link result
link = "https://www.imdb.com/search/title/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=b9121fa8-b7bb-4a3e-8887-aab822e0b5a7&pf_rd_r=3PT1F93BV1MD600GGCRY&pf_rd_s=right-6&pf_rd_t=15506&pf_rd_i=moviemeter&ref_=chtmvm_gnr_1&genres=action&explore=title_type,genres"
page = read_html(link)
# Parse elements you want to scrape
# Use SelectorGadget and past the copy and paste the selection to html_nodes
name = page %>% html_nodes(".lister-item-header a") %>% html_text()
year = page %>% html_nodes(".text-muted.unbold") %>% html_text()
rating = page %>% html_nodes(".ratings-imdb-rating") %>% html_text()
synopsis = page %>% html_nodes(".text-muted+ .text-muted , .ratings-bar+ .text-muted") %>% html_text()
# Create data frames
df_names = data.frame(name, year, rating, synopsis, stringsAsFactors = FALSE)
# Parse elements you want to scrape
# Use SelectorGadget and past the copy and paste the selection to html_nodes
name = page %>% html_nodes(".lister-item-header a") %>% html_text()
name
year = page %>% html_nodes(".text-muted.unbold") %>% html_text()
year
rating = page %>% html_nodes(".ratings-imdb-rating") %>% html_text()
rating
rating = page %>% html_nodes(".ratings-imdb-rating strong") %>% html_text()
rating
synopsis = page %>% html_nodes(".text-muted+ .text-muted , .ratings-bar+ .text-muted") %>% html_text()
synopsis
# Create data frames
df_names = data.frame(name, year, rating, synopsis, stringsAsFactors = FALSE)
# Create data frames
df_names = data.frame(name, year, synopsis, stringsAsFactors = FALSE)
View(df_names)                           #view created data frames
# add the following element for linking to the required link
movie_links = page %>% html_nodes("same as in name above") %>%
html_attr("href") %>% paste("https://www.imdb.com", ., sep = "")
# add the following element for linking to the required link
movie_links = page %>% html_nodes(".lister-item-header a") %>%
html_attr("href") %>% paste("https://www.imdb.com", ., sep = "")
movie_links
# add the following function to scrape the casting in the second page
get_cast = function(movie_links) {
movie_page = read_html(movie_links)
movie_cast = movie_page %>% html_nodes(".primary_photo+ td a") %>%
html_text() %>%
paste(collapse = ",")        #put multiple items in single column
return(movie_cast)
}
cast = sapply(movie_links, FUN = get_cast)
df_names = data.frame(name, year, synopsis, cast, stringsAsFactors = FALSE)
View(df_names)                           #view created data frames
cast = sapply(movie_links, FUN = get_cast, USE.NAMES = FALSE)
df_names = data.frame(name, year, synopsis, cast, stringsAsFactors = FALSE)
View(df_names)                           #view created data frames
keywords = "child abuse"
link = "https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=keywords&oq="
page = read_html(link)
page
title = page %>% html_nodes(".gs_rt a") %>% html_text()
title
keywords
keywords = child abuse
keywords = as.character("child abuse")
keywords
link = c("https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=,keywords,&oq=")
page = read_html(link)
page
title = page %>% html_nodes(".gs_rt a") %>% html_text()
title
link = "https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=mobile+learning&oq="
page = read_html(link)
title = page %>% html_nodes(".gs_rt a") %>% html_text()
title
author = page %>% html_nodes(".gs_a a") %>% html_text()
author
abstract = page %>% html_nodes(".gs_rs") %>% html_text()
abstract
df_search = data.frame(title, author, abstract)
df_search = data.frame(title, author, abstract, stringsAsFactors = F)
abstract = page %>% html_nodes(".gs_rs") %>% html_text() %>% paste(collapse = ",")
df_search = data.frame(title, author, abstract, stringsAsFactors = F)
df_search = data.frame(title, abstract, stringsAsFactors = F)
df_search
View(df_search)
title = page %>% html_nodes(".gs_rt a") %>% html_text()
author = page %>% html_nodes(".gs_a a") %>% html_text() %>% paste(collapse = ",")
abstract = page %>% html_nodes(".gs_rs") %>% html_text()
df_search = data.frame(title, author, abstract, stringsAsFactors = F)
View(df_search)
title = page %>% html_nodes(".gs_rt a") %>% html_text()
author = page %>% html_nodes(".gs_a a:nth-child(1)") %>% html_text() # %>% paste(collapse = ",")
abstract = page %>% html_nodes(".gs_rs") %>% html_text()
df_search = data.frame(title, author, abstract, stringsAsFactors = F)
View(df_search)
# Load reqiuired library
library(rvest)
library(dplyr)
keywords = as.character("child abuse")
# link = "https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=mobile+learning&oq="
link = paste0("https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=",
keywords,
"&oq=")
page = read_html(link)
# link = "https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=mobile+learning&oq="
link = paste0("https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=",
keywords, "&oq=")
page = read_html(link)
keywords = "child abuse"
# link = "https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=mobile+learning&oq="
link = paste0("https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=",
keywords, "&oq=")
page = read_html(link)
page = read_html(link)
# link = "https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=mobile+learning&oq="
link = paste0("https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=",
"mobile+learning", "&oq=")
page = read_html(link)
# link = "https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=mobile+learning&oq="
link = paste0("https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=",
"mobile learning", "&oq=")
page = read_html(link)
keywords = "child+abuse"
# link = "https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=mobile+learning&oq="
link = paste0("https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=",
keywords, "&oq=")
page = read_html(link)
title = page %>% html_nodes(".gs_rt a") %>% html_text()
author = page %>% html_nodes(".gs_a a:nth-child(1)") %>% html_text() # %>% paste(collapse = ",")
abstract = page %>% html_nodes(".gs_rs") %>% html_text()
df_search = data.frame(title, author, abstract, stringsAsFactors = F)
page
keywords = "mobile+learning"
# link = "https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=mobile+learning&oq="
link = paste0("https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=",
keywords, "&oq=")
page = read_html(link)
title = page %>% html_nodes(".gs_rt a") %>% html_text()
author = page %>% html_nodes(".gs_a a:nth-child(1)") %>% html_text() # %>% paste(collapse = ",")
abstract = page %>% html_nodes(".gs_rs") %>% html_text()
df_search = data.frame(title, author, abstract, stringsAsFactors = F)
View(df_search)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
sdata <- rnorm(n = 10000, mean = 100, sd = 15)
# Skewness and Kurtosis
library(moments)
skewness(sdata)
kurtosis(sdata)
# Histogram
library(ggplot2)
datasim <- data.frame(sdata)
ggplot(datasim, aes(x = sdata), binwidth = 15) +
geom_histogram(aes(y = ..density..),
fill = 'blue', alpha = 0.5) +
geom_density(colour = 'black') +
xlab(expression(bold('Simulated Samples'))) +
ylab(expression(bold('Density')))
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
setwd("D:/R/Training")
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
install.packages("performance")
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
install.packages("times.sty")
\documentclass{article}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{times}
update.packages("tinytex")
library(tinytex)
install.packages("tinytex")
install.packages("tinytex")
install.packages("tinytex")
tinytex::parse_install(text = "! LaTeX Error: File `times.sty' not found.")
install.packages('xfun')
install.packages("xfun")
library(tinytex)
tinytex::parse_install(text = "! LaTeX Error: File `times.sty' not found.")
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(Rcmdr)
View(newODLExpStudent)
View(newODLExpStudent)
library(dplyr)
newODLExpStudent <- ODLExpStudents %>%
select(ODLExpStudents$campus[3,5])
?`dplyr-package`
?dplyr
newODLExpStudent <- ODLExpStudents %>% filter(ODLExpStudents, campus == "3" & campus == "5")
newODLExpStudent <- ODLExpStudents %>% filter(ODLExpStudents, campus == c(3,5))
newODLExpStudent <- ODLExpStudents %>% filter(ODLExpStudents, campus == 3
)
names(campus)
newODLExpStudent <- ODLExpStudents %>% group_by(campus)
View(newODLExpStudent)
newODLExpStudent <- ODLExpStudents %>% select_if(campus==3)
newODLExpStudent <- ODLExpStudents %>% select_if(ODLExpStudents$campus=c(3,5))
newODLExpStudent <- ODLExpStudents %>% select_if(ODLExpStudents$campus==c(3,5))
newODLExpStudent <- ODLExpStudents %>% select_if(ODLExpStudents$campus[c(3,5):])
newODLExpStudent <- ODLExpStudents %>% select_if(ODLExpStudents$campus==3)
newODLExpStudent <- ODLExpStudents %>% Filters
newODLExpStudent <- ODLExpStudents %>% subset(campus == c(3,5))
View(newODLExpStudent)
str(newODLExpStudent)
data_odl <- data.frame(newODLExpStudent)
data_odl
summary(data_odl$gender1)
data_odl$gender <- data_odl %>% merge(gender1, gender2)
data_odl$gender <- data_odl %>% merge(data_odl$gender1, data_odl$gender2)
data_odl$gender <- data_odl %>% merge_by(data_odl$gender1, data_odl$gender2)
data_odl$gender <- data_odl %>% mergeRows(data_odl$gender1, data_odl$gender2, common.only = FALSE)
data_odl$gender <- data_odl %>% mergeRows(data_odl$gender1, data_odl$gender2, common.only = T)
data_odl$gender <- data_odl %>% mergeRows(data_odl$gender1, data_odl$gender2)
data_odl$gender <- data_odl$gender1
head(data_odl$gender)
data_odl$gender[NA] <- "Female"
data_odl$gender <- dplyr::mutate(gender = replace_na(gender, "Female"))
library(dplyr)
data_odl$gender <- dplyr::mutate(gender = replace_na(gender, "Female"))
library(tidyr)
data_odl$gender <- dplyr::mutate(gender = replace_na(gender, "Female"))
data_odl$gender1 <- dplyr::mutate(gender1 = replace_na(gender, "Female"))
data_odl$gender1 <- dplyr::mutate(gender1 = replace_na(gender1, "Female"))
data_odl <- dplyr::mutate(gender = replace_na(gender, "Female"))
data_odl <- dplyr::mutate(data_odl$gender = replace_na(data_odl$gender, "Female"))
View(data_odl)
data_odl$gender <- replace_na("Female")
data_odl <- rm(gender)
data_odl <- data.frame(newODLExpStudent)
View(data_odl)
data_odl$gender <- data_odl$gender1
summary(gender)
summary(data_odl$gender)
data_odl$gender <- data_odl$gender %>% dplyr::mutate(data_odl$gender = replace_na(data_odl$gender, "Female"))
data_odl$gender %>% replace_na("Female")
data_odl$gender %>% replace_na("Female")
str(data_odl$gender)
data_odl$gender %>% replace_na(0)
df<-data_odl
df$gender
df$gender %>% replace_na("Female")
df$gender %>% rename_if(is.null("Female"))
df$gender %>% rename_if(is.na("Female"))
fix(df)
write(df, file = "df_north.csv")
write.csv(df, file = "df_north.csv")
setwd("E:/UiTM Project/Dr Azahari")
library(ggplot2)
library(tidyverse)
df <- read.csv("df_north.csv")
head(df)
da <- data.frame(df)
dim(df)
str(df)
summary(df)
frequency(c(campus,faculty,semester,program,gender))
frequency(df)
glimpse(df)
table(df)
table(df$campus)
table(df$faculty)
table(df$program)
table(df$gender)
view(df)
library(plotly)
corrplot(df)
library(arm)
corrplot(df)
corrplot(df[7:16, ])
corrplot(df[8:16, ])
corrplot(df[,8:16])
heatmap(df[,8:16])
heatmap(df)
x <- as.matrix(df[,8:16])
heatmap(x)
corrplot(df[,8:16], color = T)
cor(df[,8:16])
plot(cor(df[,8:16]))
plot(df[,8:16])
table(df[,8:16])
rm(x)
barplot(df$campus)
df$campus
df$campus <- as.factor(df$campus)
barplot(df$campus)
plot(df$campus)
plot(df$campus)
library(Rcmdr)
setwd("D:/R/Training/dash/dash tutorial")
library(dash)
library(dashCoreComponents)
library(dashHtmlComponents)
app <- Dash$new()
app$layout(
htmlDiv(
list(
htmlH1('Hello Dash'),
htmlDiv(children = "Dash: A web application framework for R."),
dccGraph(
figure=list(
data=list(
list(
x=list(1, 2, 3),
y=list(4, 1, 2),
type='bar',
name='SF'
),
list(
x=list(1, 2, 3),
y=list(2, 4, 5),
type='bar',
name='Montr\U{00E9}al'
)
),
layout = list(title='Dash Data Visualization')
)
)
)
)
)
app$run_server()
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
library(devtools)
devtools::install_github("RamiKrispin/coronavirus", force = TRUE)
